# Titanic_Kaggle_Competition
Hey, All Data Science Enthuastihs!! Today, I have come up with the Titanic dataset, which is recommended for every data science aspirant. In this, we have two datasets, Train and test datasets. I further process this data to predict the survival of the passengers of the Titanic ship in 1917. I took the prediction by starting with data preprocessing by cleaning the
given dataset and then fitting it into Some classification models to check the accuracy. I used the Logistic model, Decision Tree Classifier, Random Forest Classification, Gradient Boosting Classifier, and XGB Classifier. 

In this repository, I have posted two Python files. The Pratice file contains the simple way or method of approaching this dataset and an accuracy score of 0.86, the highest among by using the Random Forest Classifier. The Contest file has a high level of data analysis by using feature engineering concepts and obtaining an accuracy score of 0.87 using the same Random Forest Classifier. 

This dataset is a must for beginners, trying out the data science field and want to explore this domain as I do. I have referred to some of the methods from Kaggle for better accuracy. For the detailed analysis, I will post an article on achieving higher prediction scores on my medium page.
